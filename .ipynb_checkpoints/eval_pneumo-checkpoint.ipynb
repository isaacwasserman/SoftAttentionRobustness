{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import foolbox\n",
    "import eagerpy as ep\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../pneumothorax/ChestX-ray14-resized/binary\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    batch_size=16,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "test_batches = test_batches.map(lambda x,y: (tf.keras.applications.resnet50.preprocess_input(x),y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = []\n",
    "maxs = []\n",
    "for batch in test_batches:\n",
    "    mins.append(tf.math.reduce_min(batch[0]))\n",
    "    maxs.append(tf.math.reduce_max(batch[0]))\n",
    "print(float(tf.math.reduce_min(mins)), float(tf.math.reduce_max(maxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pneumothorax/Pneumo_model.pkl\",\"rb\") as file:\n",
    "    model_without_attention = pickle.load(file)\n",
    "with open(\"../pneumothorax/Pneumo+SA_model.pkl\",\"rb\") as file:\n",
    "    model_with_attention = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"with_attention\"\n",
    "models = {\"with_attention\":model_with_attention, \"without_attention\":model_without_attention}\n",
    "model = models[model_name]\n",
    "preprocessing = dict()\n",
    "bounds = (-123.69, 151.062)\n",
    "fmodel = foolbox.TensorFlowModel(model, bounds=bounds, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_accs = []\n",
    "batch_weights = []\n",
    "for i,(x,y) in zip(range(len(test_batches)),test_batches):\n",
    "    acc = foolbox.utils.accuracy(fmodel, x, tf.argmax(y, axis=1))\n",
    "    batch_accs.append(acc)\n",
    "    batch_weights.append(y.shape[0])\n",
    "s1 = 0\n",
    "s2 = sum(batch_weights)\n",
    "for i in range(len(batch_accs)):\n",
    "    s1 += batch_accs[i] * batch_weights[i]\n",
    "print(\"unperturbed acc:\",s1/s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = foolbox.attacks.LinfAdamProjectedGradientDescentAttack()\n",
    "for model in [model_without_attention, model_with_attention]:\n",
    "    fmodel = foolbox.TensorFlowModel(model, bounds=bounds, preprocessing=preprocessing)\n",
    "    for epsilon in [0.00125, 0.0025, 0.005, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32]:\n",
    "        adv_batches = []\n",
    "        labels = []\n",
    "        print(\"epsilon =\", epsilon)\n",
    "        for i,(x,y) in tqdm(zip(range(len(test_batches)),test_batches), total=len(test_batches)):\n",
    "            raw, clipped, is_adv = attack(fmodel, tf.constant(x), tf.argmax(y, axis=1), epsilons=[epsilon])\n",
    "            adv_batches.append(clipped[0])\n",
    "            labels.append(tf.argmax(y, axis=1))\n",
    "\n",
    "        batch_accs = []\n",
    "        batch_weights = []\n",
    "        for (batch,label) in zip(adv_batches, labels):\n",
    "            x = np.array(batch)\n",
    "            y = np.array(label)\n",
    "            acc = foolbox.utils.accuracy(fmodel, x, y)\n",
    "            batch_accs.append(acc)\n",
    "            batch_weights.append(y.shape[0])\n",
    "        s1 = 0\n",
    "        s2 = sum(batch_weights)\n",
    "        for i in range(len(batch_accs)):\n",
    "            s1 += batch_accs[i] * batch_weights[i]\n",
    "        print(\"perturbed acc:\",s1/s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `FGSM()`\n",
    "\n",
    "| Model/Epsilon     | 0                   | 0.00125             | 0.0025              | 0.005               | 0.01                | 0.02                | 0.04                | 0.08               | 0.16                | 0.32                |\n",
    "| ----------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- |------------------- | ------------------- | ------------------- |\n",
    "| Without Attention | 0.8972455557958995  | 0.8972455557726119  | 0.8972455557958995  | 0.8964641531782007  | 0.8952920492400087  | 0.8931431920762686  | 0.8884547763467883  | 0.8792732955771839 | 0.8587614769091665  | 0.786872436057592   |\n",
    "| With Attention    | 0.8829849580345407  | 0.8827896073451846  | 0.8825942567024038  | 0.8823989060596228  | 0.8816175034535678  | 0.879859347540458   | 0.8763430357608135  | 0.868333658941045  | 0.8472357882631782  | 0.792146903715415   |\n",
    "\n",
    "Using `LinfAdamProjectedGradientDescentAttack()`\n",
    "\n",
    "| Model/Epsilon     | 0                   | 0.00125             | 0.0025              | 0.005               | 0.01                | 0.02                | 0.04                | 0.08                | 0.16                | 0.32                |\n",
    "| ----------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- |\n",
    "| Without Attention | 0.8972455557958995  | 0.8972455558075433  | 0.8972455557726119  | 0.8964641531549131  | 0.895682750560502   | 0.8939245946706796  | 0.8892361789528432  | 0.8814221527874994  | 0.8636452432232086  | 0.8048446962646638  |\n",
    "| With Attention    | 0.8829849580345407  | 0.8827896073684722  | 0.8825942567024038  | 0.8823989060829105  | 0.8820082047391297  | 0.8800546981948827  | 0.8771244383901562  | 0.8704825161397166  | 0.8534870092164122  | 0.8052353975618693  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_batches = test_batches.take(1)\n",
    "attack = foolbox.attacks.LinfPGD()\n",
    "perturbations = {}\n",
    "for epsilon in [0.08, 0.16, 0.32]: #[0.00125, 0.0025, 0.005, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32]:\n",
    "    adv_batches = []\n",
    "    labels = []\n",
    "    print(\"epsilon =\", epsilon)\n",
    "    for i,(x,y) in tqdm(zip(range(len(sample_test_batches)),sample_test_batches), total=len(sample_test_batches)):\n",
    "        raw, clipped, is_adv = attack(fmodel, tf.constant(x), tf.argmax(y, axis=1), epsilons=[epsilon])\n",
    "        adv_batches.append(clipped[0])\n",
    "        labels.append(tf.argmax(y, axis=1))\n",
    "    perturbations[epsilon] = (adv_batches, labels, is_adv)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    # if model_name == \"with_attention\":\n",
    "    #     last_conv_layer_name = \"soft_attention\"\n",
    "    #     grad_model = tf.keras.models.Model(\n",
    "    #         [model.inputs], [model.get_layer(last_conv_layer_name).output[0], model.output]\n",
    "    #     )\n",
    "    # else:\n",
    "    #     last_conv_layer_name = \"conv5_block3_out\"\n",
    "    #     grad_model = tf.keras.models.Model(\n",
    "    #         [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    #     )\n",
    "    last_conv_layer_name = \"conv5_block3_out\"\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.32\n",
    "batch_i = 0\n",
    "unperturbed_batches = []\n",
    "for batch in sample_test_batches:\n",
    "    unperturbed_batches.append(batch)\n",
    "unperturbed_batch = unperturbed_batches[batch_i][0]\n",
    "perturbed_batch = perturbations[epsilon][0][batch_i]\n",
    "true_labels = perturbations[epsilon][1][batch_i]\n",
    "is_adv = perturbations[epsilon][2][batch_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpert_pert_label_trios = []\n",
    "for i in range(len(perturbed_batch)):\n",
    "    unpert_pert_label_trios.append((unperturbed_batch[i], perturbed_batch[i], true_labels[i], is_adv[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_preprocess(x):\n",
    "    copy = x.copy()\n",
    "    copy[:,:,0] += 103.939\n",
    "    copy[:,:,1] += 116.779\n",
    "    copy[:,:,2] += 123.68\n",
    "    copy = copy[:,:,(2, 1, 0)]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_i in range(len(unpert_pert_label_trios)):\n",
    "    fig, axs = plt.subplots(2,3)\n",
    "    fig.set_figwidth(12)\n",
    "    fig.set_figheight(8)\n",
    "\n",
    "    unperturbed_image = unpert_pert_label_trios[image_i][0]\n",
    "    unperturbed_image_for_display = invert_preprocess(unperturbed_image.numpy())\n",
    "    unperturbed_image_for_display *= 255 / (np.max(invert_preprocess(unperturbed_image.numpy()).astype(int)))\n",
    "    unperturbed_image_for_display = unperturbed_image_for_display.astype(int)\n",
    "    axs[0,0].imshow(unperturbed_image_for_display)\n",
    "    axs[0,0].title.set_text(f'Unperturbed ({unpert_pert_label_trios[image_i][2]})')\n",
    "\n",
    "    perturbed_image = unpert_pert_label_trios[image_i][1]\n",
    "    perturbed_image_for_display = invert_preprocess(perturbed_image.numpy())\n",
    "    perturbed_image_for_display *= 255 / (np.max(invert_preprocess(perturbed_image.numpy()).astype(int)))\n",
    "    perturbed_image_for_display = perturbed_image_for_display.astype(int)\n",
    "    axs[0,1].imshow(perturbed_image_for_display)\n",
    "    axs[0,1].title.set_text(f'Perturbed ({int(unpert_pert_label_trios[image_i][3])})')\n",
    "\n",
    "    diff = cv2.absdiff(unperturbed_image.numpy(), perturbed_image.numpy())\n",
    "    diff *= 255 / np.max(diff)\n",
    "    axs[0,2].imshow(diff.astype(int))\n",
    "    axs[0,2].title.set_text(\"Difference (scaled)\")\n",
    "\n",
    "    unperturbed_gradcam = make_gradcam_heatmap(unperturbed_image.numpy().reshape((1,224,224,3)), model)\n",
    "    axs[1,0].imshow(unperturbed_gradcam)\n",
    "    perturbed_gradcam = make_gradcam_heatmap(perturbed_image.numpy().reshape((1,224,224,3)), model)\n",
    "    axs[1,1].imshow(perturbed_gradcam)\n",
    "\n",
    "    diff = cv2.absdiff(unperturbed_gradcam, perturbed_gradcam)\n",
    "    diff *= 255 / np.max(diff)\n",
    "    axs[1,2].imshow(diff.astype(int))\n",
    "\n",
    "    for ax in axs.reshape((6)):\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'visualizations/pneumo/eps_{epsilon}/{model_name}_from_conv/{image_i:02}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc4865d42a7b96bf49940e03a1d33c3e32ae20f8de81d71d36a73e19abe31532"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
