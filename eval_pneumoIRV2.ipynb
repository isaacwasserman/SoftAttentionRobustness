{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import foolbox\n",
    "import eagerpy as ep\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "test_batches = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"datasets/pneumothorax\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(299, 299),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "test_batches = test_batches.map(lambda x,y: (tf.keras.applications.inception_resnet_v2.preprocess_input(x),y))\n",
    "test_batches = test_batches.take(52)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/PneumoIRV2_model.pkl\",\"rb\") as file:\n",
    "    model_without_attention = pickle.load(file)\n",
    "with open(\"models/PneumoIRV2+SA_model.pkl\",\"rb\") as file:\n",
    "    model_with_attention = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epsilons = [0, 0.0003125, 0.000625, 0.00125, 0.0025, 0.005, 0.01]\n",
    "attack = foolbox.attacks.LinfPGD()\n",
    "for model in [model_without_attention, model_with_attention]:\n",
    "    fmodel = foolbox.TensorFlowModel(model, bounds=(-1,1), preprocessing={})\n",
    "    for epsilon in epsilons:\n",
    "        if epsilon == 0:\n",
    "            batch_accs = []\n",
    "            batch_weights = []\n",
    "            for i,(x,y) in zip(range(len(test_batches)),test_batches):\n",
    "                acc = foolbox.utils.accuracy(fmodel, x, tf.argmax(y, axis=1))\n",
    "                batch_accs.append(acc)\n",
    "                batch_weights.append(y.shape[0])\n",
    "            s1 = 0\n",
    "            s2 = sum(batch_weights)\n",
    "            for i in range(len(batch_accs)):\n",
    "                s1 += batch_accs[i] * batch_weights[i]\n",
    "            print(\"unperturbed acc:\",s1/s2)\n",
    "            continue\n",
    "        adv_batches = []\n",
    "        labels = []\n",
    "        print(\"epsilon =\", epsilon)\n",
    "        for i,(x,y) in tqdm(zip(range(len(test_batches)),test_batches), total=len(test_batches)):\n",
    "            raw, clipped, is_adv = attack(fmodel, tf.constant(x), tf.argmax(y, axis=1), epsilons=[epsilon])\n",
    "            adv_batches.append(clipped[0])\n",
    "            labels.append(tf.argmax(y, axis=1))\n",
    "\n",
    "        batch_accs = []\n",
    "        batch_weights = []\n",
    "        for (batch,label) in zip(adv_batches, labels):\n",
    "            x = np.array(batch)\n",
    "            y = np.array(label)\n",
    "            acc = foolbox.utils.accuracy(fmodel, x, y)\n",
    "            batch_accs.append(acc)\n",
    "            batch_weights.append(y.shape[0])\n",
    "        s1 = 0\n",
    "        s2 = sum(batch_weights)\n",
    "        for i in range(len(batch_accs)):\n",
    "            s1 += batch_accs[i] * batch_weights[i]\n",
    "        print(\"perturbed acc:\",s1/s2,\"\\n\\n\")\n",
    "        if s1/s2 == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `LinfPGD()`\n",
    "\n",
    "| Model/Epsilon     | 0                   | 0.0003125           | 0.000625            | 0.00125             | 0.0025              | 0.005                 | 0.01                |\n",
    "| ----------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- | -------------------   | ------------------- |\n",
    "| Without Attention | 0.9855769230769231  | 0.984375  | 0.9819711538461539  | 0.96875 | 0.9447115384615384 | 0.7403846153846154 | 0.13701923076923078                 |\n",
    "| With Attention    | 0.9867788461538461  | 0.9723557692307693 | 0.9495192307692307  | 0.8173076923076923 | 0.33413461538461536 | 0.33413461538461536 | 0.0                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, pred_index=None):\n",
    "    if len(model.layers) == 752:\n",
    "        last_conv_layer_name = \"conv2d_195\"\n",
    "    elif len(model.layers) == 756:\n",
    "        last_conv_layer_name = \"conv2d_195\"\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def invert_preprocess(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        copy = x.copy()\n",
    "    else:\n",
    "        copy = x.numpy()\n",
    "    copy += 1.\n",
    "    copy *= 127.5\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"with_attention\":model_with_attention, \"without_attention\":model_without_attention}\n",
    "preprocessing = dict()\n",
    "bounds = (-1, 1)\n",
    "\n",
    "sample_test_batches = test_batches.take(1)\n",
    "attack = foolbox.attacks.LinfPGD()\n",
    "perturbations = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(model_name)\n",
    "    model = models[model_name]\n",
    "    fmodel = foolbox.TensorFlowModel(model, bounds=bounds, preprocessing=preprocessing)\n",
    "\n",
    "    print(\"Generating Perturbations...\")\n",
    "    for epsilon in epsilons:\n",
    "        adv_batches = []\n",
    "        labels = []\n",
    "        print(\"epsilon =\", epsilon)\n",
    "        for i,(x,y) in tqdm(zip(range(len(sample_test_batches)),sample_test_batches), total=len(sample_test_batches)):\n",
    "            raw, clipped, is_adv = attack(fmodel, tf.constant(x), tf.argmax(y, axis=1), epsilons=[epsilon])\n",
    "            adv_batches.append(clipped[0])\n",
    "            labels.append(tf.argmax(y, axis=1))\n",
    "        perturbations[epsilon] = (adv_batches, labels, is_adv)\n",
    "\n",
    "    print(\"Graphing Perturbations\")\n",
    "    for epsilon in epsilons:\n",
    "        print(epsilon)\n",
    "        batch_i = 0\n",
    "        unperturbed_batches = []\n",
    "        for batch in sample_test_batches:\n",
    "            unperturbed_batches.append(batch)\n",
    "        unperturbed_batch = unperturbed_batches[batch_i][0]\n",
    "        perturbed_batch = perturbations[epsilon][0][batch_i]\n",
    "        true_labels = perturbations[epsilon][1][batch_i]\n",
    "        is_adv = perturbations[epsilon][2][batch_i]\n",
    "\n",
    "        unpert_pert_label_trios = []\n",
    "        for i in range(len(perturbed_batch)):\n",
    "            unpert_pert_label_trios.append((unperturbed_batch[i], perturbed_batch[i], true_labels[i], is_adv[i]))\n",
    "\n",
    "        for image_i in range(len(unpert_pert_label_trios)):\n",
    "            fig, axs = plt.subplots(2,3)\n",
    "            fig.set_figwidth(12)\n",
    "            fig.set_figheight(8)\n",
    "\n",
    "            unperturbed_image = unpert_pert_label_trios[image_i][0]\n",
    "            unperturbed_image_for_display = invert_preprocess(unperturbed_image.numpy())\n",
    "            unperturbed_image_for_display *= 255 / (np.max(invert_preprocess(unperturbed_image.numpy()).astype(int)))\n",
    "            unperturbed_image_for_display = unperturbed_image_for_display.astype(int)\n",
    "            axs[0,0].imshow(unperturbed_image_for_display)\n",
    "            axs[0,0].title.set_text(f'Unperturbed ({unpert_pert_label_trios[image_i][2]})')\n",
    "\n",
    "            perturbed_image = unpert_pert_label_trios[image_i][1]\n",
    "            perturbed_image_for_display = invert_preprocess(perturbed_image.numpy())\n",
    "            perturbed_image_for_display *= 255 / (np.max(invert_preprocess(perturbed_image.numpy()).astype(int)))\n",
    "            perturbed_image_for_display = perturbed_image_for_display.astype(int)\n",
    "            axs[0,1].imshow(perturbed_image_for_display)\n",
    "            axs[0,1].title.set_text(f'Perturbed ({int(unpert_pert_label_trios[image_i][3])})')\n",
    "\n",
    "            diff = cv2.absdiff(unperturbed_image.numpy(), perturbed_image.numpy())\n",
    "            diff *= 255 / np.max(diff)\n",
    "            axs[0,2].imshow(diff.astype(int))\n",
    "            axs[0,2].title.set_text(\"Difference (scaled)\")\n",
    "\n",
    "            unperturbed_gradcam = make_gradcam_heatmap(unperturbed_image.numpy().reshape((1,299,299,3)), model)\n",
    "            axs[1,0].imshow(unperturbed_gradcam)\n",
    "            perturbed_gradcam = make_gradcam_heatmap(perturbed_image.numpy().reshape((1,299,299,3)), model)\n",
    "            axs[1,1].imshow(perturbed_gradcam)\n",
    "\n",
    "            diff = cv2.absdiff(unperturbed_gradcam, perturbed_gradcam)\n",
    "            diff *= 255 / np.max(diff)\n",
    "            axs[1,2].imshow(diff.astype(int))\n",
    "\n",
    "            for ax in axs.reshape((6)):\n",
    "                ax.axis(\"off\")\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            path = f'visualizations/IRV2/pneumo/eps_{epsilon}/{model_name}/'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            plt.savefig(path + f'{image_i:02}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9df139cf4fd7fbfed7596b00795d916641fdf384a73a205999ad45fcffc5436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
