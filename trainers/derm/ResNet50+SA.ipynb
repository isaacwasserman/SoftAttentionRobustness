{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Aa36bMKLze3z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from  matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,GlobalAveragePooling2D,BatchNormalization,Dropout\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lnzRzk7e44HL",
    "outputId": "6d1e2d2f-1669-42a6-f6a7-45a52b73ce41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>train_test_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "      <td>duplicates</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset is_duplicate train_test_split  \n",
       "0  vidir_modern   duplicates            train  \n",
       "1  vidir_modern   duplicates            train  \n",
       "2  vidir_modern   duplicates            train  \n",
       "3  vidir_modern   duplicates            train  \n",
       "4  vidir_modern   duplicates            train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv('../../HAM10000_metadata')\n",
    "data_pd.head()\n",
    "train_dir = \"HAM10000_images_train/\"\n",
    "test_dir = \"HAM10000_images_test/\"\n",
    "df_count = data_pd.groupby('lesion_id').count()\n",
    "df_count.head()\n",
    "df_count = df_count[df_count['dx'] == 1]\n",
    "df_count.reset_index(inplace=True)\n",
    "def duplicates(x):\n",
    "    unique = set(df_count['lesion_id'])\n",
    "    if x in unique:\n",
    "        return 'no' \n",
    "    else:\n",
    "        return 'duplicates'\n",
    "data_pd['is_duplicate'] = data_pd['lesion_id'].apply(duplicates)\n",
    "data_pd.head()\n",
    "df_count = data_pd[data_pd['is_duplicate'] == 'no']\n",
    "train, test_df = train_test_split(df_count, test_size=0.15, stratify=df_count['dx'])\n",
    "def identify_trainOrtest(x):\n",
    "    test_data = set(test_df['image_id'])\n",
    "    if str(x) in test_data:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "#creating train_df\n",
    "data_pd['train_test_split'] = data_pd['image_id'].apply(identify_trainOrtest)\n",
    "train_df = data_pd[data_pd['train_test_split'] == 'train']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wNisha_gM3_Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Batches: \n",
      "Found 51699 images belonging to 7 classes.\n",
      "\n",
      "Test Batches: \n",
      "Found 828 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = '../Augmentation/HAM10000_images_train'\n",
    "test_path = '../Augmentation/HAM10000_images_test'\n",
    "batch_size= 16\n",
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\n",
    "image_size = 224\n",
    "print(\"\\nTrain Batches: \")\n",
    "train_batches = datagen.flow_from_directory(directory=train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches =datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AbwfHcsOPKYB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:08:00.376738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.404758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.405027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.405389: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-20 18:08:00.405715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.405963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.406092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.815012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.815189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.815306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-20 18:08:00.815395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7088 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " soft_attention (SoftAttention)  [(None, 7, 7, 2048)  294928     ['conv5_block3_out[0][0]']       \n",
      "                                , (None, 16, 7, 7)]                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 2048)  0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 4, 4, 2048)   0           ['soft_attention[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 4, 4096)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 4, 4, 4096)   0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4, 4, 4096)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 4096)        0           ['dropout[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 7)            28679       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,911,319\n",
      "Trainable params: 23,858,199\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Soft Attention\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer,InputSpec\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "\n",
    "resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    ")\n",
    "\n",
    "# Exclude the last 3 layers of the model.\n",
    "conv = resnet.layers[-3].output\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,ch=int(conv.shape[-1]),m=16,concat_with_x=False,aggregate=False,**kwargs):\n",
    "        self.channels=int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "\n",
    "        \n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.i_shape = input_shape\n",
    "\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "    \n",
    "        self.out_attention_maps_shape = input_shape[0:1]+(self.multiheads,)+input_shape[1:-1]\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "\n",
    "            self.out_features_shape = input_shape[:-1]+(input_shape[-1]+(input_shape[-1]*self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1]+(input_shape[-1]*2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "        \n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                        initializer='he_uniform',\n",
    "                                        name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        exp_x = K.expand_dims(x,axis=-1)\n",
    "\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                     kernel=self.kernel_conv3d,\n",
    "                     strides=(1,1,self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d,\n",
    "                        self.bias_conv3d)\n",
    "        conv3d = kl.Activation('relu')(conv3d)\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d,pattern=(0,4,1,2,3))\n",
    "\n",
    "        \n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d,shape=(-1, self.multiheads ,self.i_shape[1]*self.i_shape[2]))\n",
    "\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1) \n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1],self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        \n",
    "        if self.aggregate_channels==False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)       \n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha,pattern=(0,2,3,1,4))\n",
    "   \n",
    "            x_exp = K.expand_dims(x,axis=-2)\n",
    "   \n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])   \n",
    "  \n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1],self.i_shape[2],u.shape[-1]*u.shape[-2]))(u)\n",
    "\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha,pattern=(0,2,3,1))\n",
    "\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha,axis=-1)\n",
    "\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])   \n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u,x])\n",
    "        else:\n",
    "            o = u\n",
    "        \n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape): \n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(SoftAttention,self).get_config()\n",
    " \n",
    "attention_layer,map2 = SoftAttention(aggregate=True,m=16,concat_with_x=False,ch=int(conv.shape[-1]),name='soft_attention')(conv)\n",
    "attention_layer=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(attention_layer))\n",
    "conv=(MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv))\n",
    "\n",
    "conv = concatenate([conv,attention_layer])\n",
    "conv  = Activation('relu')(conv)\n",
    "conv = Dropout(0.5)(conv)\n",
    "\n",
    "output = GlobalAveragePooling2D()(conv)\n",
    "output = Dense(7, activation='softmax')(output)\n",
    "model = Model(inputs=resnet.input, outputs=output)\n",
    "\n",
    "opt1=tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=0.1)\n",
    "model.compile(optimizer=opt1,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "class_weights = {   \n",
    "                    0: 1.0,  # akiec\n",
    "                    1: 1.0,  # bcc\n",
    "                    2: 1.0,  # bkl\n",
    "                    3: 1.0,  # df\n",
    "                    4: 5.0,  # mel\n",
    "                    5: 1.0,  # nv\n",
    "                    6: 1.0,  # vasc\n",
    "                }\n",
    "\n",
    "\n",
    "checkpoint=  ModelCheckpoint(filepath = 'ResNet50+SA.hdf5',monitor='val_accuracy',save_best_only=True,save_weights_only=True)\n",
    "Earlystop = EarlyStopping(monitor='val_loss', mode='min',patience=40, min_delta=0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUzTmiZ-8hL3",
    "outputId": "a5667822-7ace-49da-f26b-896db54c720d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:08:13.298369: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918/918 [==============================] - 212s 182ms/step - loss: 2.5093 - accuracy: 0.3583 - val_loss: 436.5469 - val_accuracy: 0.0411\n",
      "Epoch 2/300\n",
      "918/918 [==============================] - 169s 184ms/step - loss: 2.2070 - accuracy: 0.4027 - val_loss: 2.4080 - val_accuracy: 0.3720\n",
      "Epoch 3/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 1.8242 - accuracy: 0.4699 - val_loss: 0.7731 - val_accuracy: 0.7114\n",
      "Epoch 4/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 1.6159 - accuracy: 0.5254 - val_loss: 1.0417 - val_accuracy: 0.6413\n",
      "Epoch 5/300\n",
      "918/918 [==============================] - 173s 188ms/step - loss: 1.4759 - accuracy: 0.5630 - val_loss: 7.8871 - val_accuracy: 0.3478\n",
      "Epoch 6/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 1.3780 - accuracy: 0.5968 - val_loss: 0.9908 - val_accuracy: 0.6691\n",
      "Epoch 7/300\n",
      "918/918 [==============================] - 172s 188ms/step - loss: 1.2826 - accuracy: 0.6238 - val_loss: 0.8422 - val_accuracy: 0.7150\n",
      "Epoch 8/300\n",
      "918/918 [==============================] - 171s 187ms/step - loss: 1.1932 - accuracy: 0.6428 - val_loss: 0.7385 - val_accuracy: 0.7138\n",
      "Epoch 9/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 1.1101 - accuracy: 0.6656 - val_loss: 0.7499 - val_accuracy: 0.7029\n",
      "Epoch 10/300\n",
      "918/918 [==============================] - 172s 188ms/step - loss: 1.0814 - accuracy: 0.6749 - val_loss: 0.6580 - val_accuracy: 0.7633\n",
      "Epoch 11/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 1.0048 - accuracy: 0.6982 - val_loss: 0.4935 - val_accuracy: 0.8140\n",
      "Epoch 12/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.9834 - accuracy: 0.7069 - val_loss: 0.6657 - val_accuracy: 0.7597\n",
      "Epoch 13/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.9700 - accuracy: 0.7135 - val_loss: 0.8380 - val_accuracy: 0.7391\n",
      "Epoch 14/300\n",
      "918/918 [==============================] - 172s 188ms/step - loss: 0.8837 - accuracy: 0.7360 - val_loss: 0.4874 - val_accuracy: 0.8285\n",
      "Epoch 15/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.8661 - accuracy: 0.7398 - val_loss: 0.4926 - val_accuracy: 0.8357\n",
      "Epoch 16/300\n",
      "918/918 [==============================] - 172s 188ms/step - loss: 0.7856 - accuracy: 0.7658 - val_loss: 0.6154 - val_accuracy: 0.7814\n",
      "Epoch 17/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.7627 - accuracy: 0.7700 - val_loss: 0.4890 - val_accuracy: 0.8273\n",
      "Epoch 18/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.7275 - accuracy: 0.7845 - val_loss: 0.5967 - val_accuracy: 0.8056\n",
      "Epoch 19/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.7450 - accuracy: 0.7770 - val_loss: 0.5475 - val_accuracy: 0.8128\n",
      "Epoch 20/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.7193 - accuracy: 0.7896 - val_loss: 0.5921 - val_accuracy: 0.7850\n",
      "Epoch 21/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.6529 - accuracy: 0.8074 - val_loss: 0.6973 - val_accuracy: 0.7524\n",
      "Epoch 22/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.6452 - accuracy: 0.8106 - val_loss: 0.6156 - val_accuracy: 0.8080\n",
      "Epoch 23/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.6249 - accuracy: 0.8158 - val_loss: 0.5899 - val_accuracy: 0.8019\n",
      "Epoch 24/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.5951 - accuracy: 0.8283 - val_loss: 0.4666 - val_accuracy: 0.8551\n",
      "Epoch 25/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.5808 - accuracy: 0.8310 - val_loss: 0.5746 - val_accuracy: 0.7995\n",
      "Epoch 26/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.5792 - accuracy: 0.8305 - val_loss: 0.5718 - val_accuracy: 0.8031\n",
      "Epoch 27/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.5342 - accuracy: 0.8425 - val_loss: 0.5275 - val_accuracy: 0.8466\n",
      "Epoch 28/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.5075 - accuracy: 0.8527 - val_loss: 0.7250 - val_accuracy: 0.7488\n",
      "Epoch 29/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.4697 - accuracy: 0.8622 - val_loss: 0.5497 - val_accuracy: 0.8418\n",
      "Epoch 30/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.4376 - accuracy: 0.8755 - val_loss: 0.5243 - val_accuracy: 0.8382\n",
      "Epoch 31/300\n",
      "918/918 [==============================] - 172s 187ms/step - loss: 0.4684 - accuracy: 0.8618 - val_loss: 0.5742 - val_accuracy: 0.8116\n",
      "Epoch 32/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.4319 - accuracy: 0.8750 - val_loss: 0.5605 - val_accuracy: 0.8249\n",
      "Epoch 33/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.4270 - accuracy: 0.8747 - val_loss: 0.5425 - val_accuracy: 0.8333\n",
      "Epoch 34/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.4466 - accuracy: 0.8736 - val_loss: 0.4712 - val_accuracy: 0.8442\n",
      "Epoch 35/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.3932 - accuracy: 0.8874 - val_loss: 0.4875 - val_accuracy: 0.8551\n",
      "Epoch 36/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.3504 - accuracy: 0.9000 - val_loss: 0.4921 - val_accuracy: 0.8575\n",
      "Epoch 37/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.3170 - accuracy: 0.9068 - val_loss: 0.5417 - val_accuracy: 0.8635\n",
      "Epoch 38/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.3641 - accuracy: 0.8978 - val_loss: 0.4128 - val_accuracy: 0.8804\n",
      "Epoch 39/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.3241 - accuracy: 0.9078 - val_loss: 0.5626 - val_accuracy: 0.8599\n",
      "Epoch 40/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.3067 - accuracy: 0.9108 - val_loss: 0.5344 - val_accuracy: 0.8611\n",
      "Epoch 41/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.2878 - accuracy: 0.9181 - val_loss: 0.5948 - val_accuracy: 0.8345\n",
      "Epoch 42/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2848 - accuracy: 0.9201 - val_loss: 0.5906 - val_accuracy: 0.8514\n",
      "Epoch 43/300\n",
      "918/918 [==============================] - 170s 186ms/step - loss: 0.2686 - accuracy: 0.9244 - val_loss: 0.5567 - val_accuracy: 0.8406\n",
      "Epoch 44/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2338 - accuracy: 0.9314 - val_loss: 0.7152 - val_accuracy: 0.7911\n",
      "Epoch 45/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.2413 - accuracy: 0.9307 - val_loss: 0.5130 - val_accuracy: 0.8744\n",
      "Epoch 46/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2658 - accuracy: 0.9259 - val_loss: 0.7432 - val_accuracy: 0.8200\n",
      "Epoch 47/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.2725 - accuracy: 0.9220 - val_loss: 0.5810 - val_accuracy: 0.8430\n",
      "Epoch 48/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2135 - accuracy: 0.9396 - val_loss: 0.7011 - val_accuracy: 0.8394\n",
      "Epoch 49/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2027 - accuracy: 0.9404 - val_loss: 0.6134 - val_accuracy: 0.8647\n",
      "Epoch 50/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2280 - accuracy: 0.9396 - val_loss: 0.5617 - val_accuracy: 0.8527\n",
      "Epoch 51/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2004 - accuracy: 0.9443 - val_loss: 0.5040 - val_accuracy: 0.8659\n",
      "Epoch 52/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1883 - accuracy: 0.9474 - val_loss: 0.5850 - val_accuracy: 0.8708\n",
      "Epoch 53/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1922 - accuracy: 0.9459 - val_loss: 0.6174 - val_accuracy: 0.8406\n",
      "Epoch 54/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1777 - accuracy: 0.9489 - val_loss: 0.6305 - val_accuracy: 0.8297\n",
      "Epoch 55/300\n",
      "918/918 [==============================] - 171s 186ms/step - loss: 0.1869 - accuracy: 0.9478 - val_loss: 0.5897 - val_accuracy: 0.8623\n",
      "Epoch 56/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.7146 - val_accuracy: 0.8140\n",
      "Epoch 57/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2818 - accuracy: 0.9221 - val_loss: 0.5522 - val_accuracy: 0.8732\n",
      "Epoch 58/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.2076 - accuracy: 0.9397 - val_loss: 0.7549 - val_accuracy: 0.8140\n",
      "Epoch 59/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1850 - accuracy: 0.9467 - val_loss: 0.6181 - val_accuracy: 0.8696\n",
      "Epoch 60/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1829 - accuracy: 0.9481 - val_loss: 0.6768 - val_accuracy: 0.8466\n",
      "Epoch 61/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1461 - accuracy: 0.9581 - val_loss: 0.8300 - val_accuracy: 0.8225\n",
      "Epoch 62/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1758 - accuracy: 0.9517 - val_loss: 0.5966 - val_accuracy: 0.8732\n",
      "Epoch 63/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1516 - accuracy: 0.9582 - val_loss: 0.6968 - val_accuracy: 0.8478\n",
      "Epoch 64/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1529 - accuracy: 0.9571 - val_loss: 0.5793 - val_accuracy: 0.8659\n",
      "Epoch 65/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1404 - accuracy: 0.9615 - val_loss: 0.6926 - val_accuracy: 0.8708\n",
      "Epoch 66/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1574 - accuracy: 0.9571 - val_loss: 0.6753 - val_accuracy: 0.8406\n",
      "Epoch 67/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1318 - accuracy: 0.9623 - val_loss: 0.7191 - val_accuracy: 0.8394\n",
      "Epoch 68/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1157 - accuracy: 0.9685 - val_loss: 0.6707 - val_accuracy: 0.8527\n",
      "Epoch 69/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1053 - accuracy: 0.9702 - val_loss: 0.6249 - val_accuracy: 0.8659\n",
      "Epoch 70/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.0899 - accuracy: 0.9759 - val_loss: 0.5851 - val_accuracy: 0.8684\n",
      "Epoch 71/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1085 - accuracy: 0.9698 - val_loss: 0.8043 - val_accuracy: 0.8140\n",
      "Epoch 72/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1023 - accuracy: 0.9715 - val_loss: 0.6606 - val_accuracy: 0.8575\n",
      "Epoch 73/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1042 - accuracy: 0.9712 - val_loss: 0.6759 - val_accuracy: 0.8732\n",
      "Epoch 74/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1143 - accuracy: 0.9688 - val_loss: 0.6720 - val_accuracy: 0.8635\n",
      "Epoch 75/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.1141 - accuracy: 0.9676 - val_loss: 0.7110 - val_accuracy: 0.8539\n",
      "Epoch 76/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.0966 - accuracy: 0.9738 - val_loss: 0.6677 - val_accuracy: 0.8684\n",
      "Epoch 77/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.0809 - accuracy: 0.9780 - val_loss: 0.7955 - val_accuracy: 0.8406\n",
      "Epoch 78/300\n",
      "918/918 [==============================] - 170s 185ms/step - loss: 0.0872 - accuracy: 0.9746 - val_loss: 0.7295 - val_accuracy: 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7caeeac5-3567-4486-8f7e-fc2b62bd5f11/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7caeeac5-3567-4486-8f7e-fc2b62bd5f11/assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    steps_per_epoch=(len(train_df)/10),\n",
    "                    epochs=300,\n",
    "                    # verbose=2,\n",
    "                    validation_data=test_batches,validation_steps=len(test_df)/batch_size,callbacks=[checkpoint,Earlystop],class_weight=class_weights)\n",
    "\n",
    "from tensorflow.keras import models\n",
    "model.load_weights(\"ResNet50+SA.hdf5\")\n",
    "with open(\"Derm+SA_model.pkl\",\"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Derm+SA_model.pkl\",\"rb\") as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 5s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYxCDDjusR-S",
    "outputId": "dfb18a18-24d1-4093-9d9a-5ded9a857aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.55      0.52      0.53        23\n",
      "         bcc       0.68      0.50      0.58        26\n",
      "         bkl       0.59      0.62      0.61        66\n",
      "          df       0.22      0.33      0.27         6\n",
      "         mel       0.45      0.44      0.45        34\n",
      "          nv       0.96      0.96      0.96       663\n",
      "        vasc       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.88       828\n",
      "   macro avg       0.64      0.61      0.62       828\n",
      "weighted avg       0.88      0.88      0.88       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#geting predictions on test dataset\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "targetnames = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "#getting the true labels per image \n",
    "y_true = test_batches.classes\n",
    "#getting the predicted labels per image \n",
    "y_prob=predictions\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_true)\n",
    "\n",
    "# Creating classification report \n",
    "report = classification_report(y_true, y_pred, target_names=targetnames)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy59Zs1jqylz",
    "outputId": "7c314b88-35c9-460f-fcc6-b63a35fe0856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9110583683373215\n",
      "Recall: 0.9021739130434783\n",
      "Accuracy: 0.9021739130434783\n",
      "weighted Roc score: 0.9731255503966255\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"weighted Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFRWOB82sDKi",
    "outputId": "ed2ee6fe-be46-41d7-c3c6-5d42ce4725d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7159154160870015\n",
      "Recall: 0.7175664063132094\n",
      "Accuracy: 0.9021739130434783\n",
      "Macro Roc score: 0.971112110278665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='macro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='macro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "print(\"Macro Roc score: \" + str(roc_auc_score(y_test,y_prob,multi_class='ovr',average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDNAPv9OsRVg",
    "outputId": "82ce7b00-a761-4c00-b456-26c75360b954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9021739130434783\n",
      "Recall: 0.9021739130434783\n",
      "Accuracy: 0.9021739130434783\n",
      "Micro Roc score: 0.9906984410371305\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \"+ str(precision_score(y_true, y_pred, average='micro')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='micro')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "tpr={}\n",
    "fpr={}\n",
    "roc_auc={}\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_prob.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "print(\"Micro Roc score: \" + str(roc_auc[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U03sRDM2sudx",
    "outputId": "d3634358-f415-457d-e2e3-2332be6055a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC score of akiec is: 0.9541452876046448\n",
      "The ROC AUC score of bcc is: 0.9782275081526952\n",
      "The ROC AUC score of bkl is: 0.9559373260160662\n",
      "The ROC AUC score of df is: 0.9817518248175183\n",
      "The ROC AUC score of mel is: 0.9523262705586013\n",
      "The ROC AUC score of nv is: 0.9758855523561406\n",
      "The ROC AUC score of vasc is: 0.9995110024449878\n"
     ]
    }
   ],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(7):\n",
    "    r = roc_auc_score(y_test[:, i], y_prob[:, i])\n",
    "    print(\"The ROC AUC score of \"+targetnames[i]+\" is: \"+str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "A5nG-b11wkep"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = dict()\n",
    "for i in range(7):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wz2--WDwHQ4",
    "outputId": "966c976d-ecca-452c-b393-464961781b50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(fpr[0], tpr[0],'v-',label='akiec: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(fpr[1], tpr[1],'c',label='bcc: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot(fpr[2], tpr[2],'b',label='bkl: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot(fpr[3], tpr[3],'g',label='df: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "plt.plot(fpr[4], tpr[4],'y',label='mel: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "plt.plot(fpr[5], tpr[5],'o-',label='nv: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "plt.plot(fpr[6], tpr[6],'r',label='vasc: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet50+SA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc4865d42a7b96bf49940e03a1d33c3e32ae20f8de81d71d36a73e19abe31532"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
