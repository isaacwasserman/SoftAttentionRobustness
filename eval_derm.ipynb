{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/envs/tf/lib/python3.9/site-packages/art/estimators/certification/__init__.py:12: UserWarning: PyTorch not found. Not importing DeepZ functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ functionality\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod, AutoAttack, AutoProjectedGradientDescent\n",
    "from art.estimators.classification import KerasClassifier, TensorFlowV2Classifier\n",
    "from art.utils import load_mnist\n",
    "import foolbox as fb\n",
    "import eagerpy as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Batches: \n",
      "Found 828 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_path = '../Attention-based-Skin-Cancer-Classification/Ham10000 models/Augmentation/HAM10000_images_test'\n",
    "batch_size= 16\n",
    "datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\n",
    "image_size = 224\n",
    "\n",
    "print(\"\\nTest Batches: \")\n",
    "test_batches = datagen.flow_from_directory(test_path,\n",
    "                                           target_size=(image_size,image_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/isaac/code/AdversarialEval/eval_derm.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/isaac/code/AdversarialEval/eval_derm.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m test_batches:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/isaac/code/AdversarialEval/eval_derm.ipynb#ch0000010?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmax(el[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/preprocessing/image.py:148\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 148\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/preprocessing/image.py:160\u001b[0m, in \u001b[0;36mIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m   index_array \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_generator)\n\u001b[1;32m    158\u001b[0m \u001b[39m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m# so it can be done in parallel\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/preprocessing/image.py:337\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    335\u001b[0m filepaths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepaths\n\u001b[1;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(index_array):\n\u001b[0;32m--> 337\u001b[0m   img \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39;49mload_img(\n\u001b[1;32m    338\u001b[0m       filepaths[j],\n\u001b[1;32m    339\u001b[0m       color_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolor_mode,\n\u001b[1;32m    340\u001b[0m       target_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_size,\n\u001b[1;32m    341\u001b[0m       interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation,\n\u001b[1;32m    342\u001b[0m       keep_aspect_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeep_aspect_ratio)\n\u001b[1;32m    343\u001b[0m   x \u001b[39m=\u001b[39m image_utils\u001b[39m.\u001b[39mimg_to_array(img, data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format)\n\u001b[1;32m    344\u001b[0m   \u001b[39m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[1;32m    345\u001b[0m   \u001b[39m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/image_utils.py:443\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    441\u001b[0m       img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mresize(width_height_tuple, resample, box\u001b[39m=\u001b[39mcrop_box)\n\u001b[1;32m    442\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m       img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mresize(width_height_tuple, resample)\n\u001b[1;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/PIL/Image.py:2043\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mresize(size, resample, box)\n\u001b[1;32m   2041\u001b[0m     \u001b[39mreturn\u001b[39;00m im\u001b[39m.\u001b[39mconvert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode)\n\u001b[0;32m-> 2043\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   2045\u001b[0m \u001b[39mif\u001b[39;00m reducing_gap \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m resample \u001b[39m!=\u001b[39m Resampling\u001b[39m.\u001b[39mNEAREST:\n\u001b[1;32m   2046\u001b[0m     factor_x \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m size[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m reducing_gap) \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/PIL/ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    256\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 257\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for el in test_batches:\n",
    "    print(np.max(el[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:13:13.502107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.529074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.529238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.530047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-23 12:13:13.530380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.530533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.530656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.961943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.962127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.962247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:13:13.962337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6542 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "with open(\"../Attention-based-Skin-Cancer-Classification/Ham10000 models/Model without Soft Attention/Derm_model.pkl\",\"rb\") as file:\n",
    "    model_without_attention = pickle.load(file)\n",
    "with open(\"../Attention-based-Skin-Cancer-Classification/Ham10000 models/Model With Soft Attention/Derm+SA_model.pkl\",\"rb\") as file:\n",
    "    model_with_attention = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:20:07.372924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:20:07.373259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:20:07.373443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:20:07.373680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:20:07.373865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 12:20:07.374121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 6542 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = model_with_attention\n",
    "preprocessing = dict()\n",
    "bounds = (-1, 1)\n",
    "fmodel = fb.TensorFlowModel(model, bounds=bounds, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unperturbed acc: 0.8804347823207505\n"
     ]
    }
   ],
   "source": [
    "batch_accs = []\n",
    "batch_weights = []\n",
    "for i,(x,y) in zip(range(len(test_batches)),test_batches):\n",
    "    # if i == 0:\n",
    "    #     print(type(x),y)\n",
    "    acc = fb.utils.accuracy(fmodel, x, tf.argmax(y, axis=1))\n",
    "    batch_accs.append(acc)\n",
    "    batch_weights.append(y.shape[0])\n",
    "s1 = 0\n",
    "s2 = sum(batch_weights)\n",
    "for i in range(len(batch_accs)):\n",
    "    s1 += batch_accs[i] * batch_weights[i]\n",
    "print(\"unperturbed acc:\",s1/s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturbed acc: 0.7946859903381642\n"
     ]
    }
   ],
   "source": [
    "attack = fb.attacks.LinfPGD()\n",
    "adv_batches = []\n",
    "labels = []\n",
    "for i,(x,y) in zip(range(len(test_batches)),test_batches):\n",
    "    raw, clipped, is_adv = attack(fmodel, tf.constant(x), tf.argmax(y, axis=1), epsilons=[0.00125])\n",
    "    adv_batches.append(clipped[0])\n",
    "    labels.append(tf.argmax(y, axis=1))\n",
    "\n",
    "batch_accs = []\n",
    "batch_weights = []\n",
    "for (batch,label) in zip(adv_batches, labels):\n",
    "    x = np.array(batch)\n",
    "    y = np.array(label)\n",
    "    acc = fb.utils.accuracy(fmodel, x, y)\n",
    "    batch_accs.append(acc)\n",
    "    batch_weights.append(y.shape[0])\n",
    "s1 = 0\n",
    "s2 = sum(batch_weights)\n",
    "for i in range(len(batch_accs)):\n",
    "    s1 += batch_accs[i] * batch_weights[i]\n",
    "print(\"perturbed acc:\",s1/s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00125"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0025/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `LinfPGD()`\n",
    "| Model/Epsilon     | 0                   | 0.00125             | 0.0025              | 0.005               | 0.01                |\n",
    "| ----------------- | ------------------- | ------------------- | ------------------- | ------------------- | ------------------- |\n",
    "| Without Attention | 0.9045893722686215  | 0.6871980679207954  | 0.21618357473525449 | 0.01207729472198348 | 0.0                 |\n",
    "| With Attention    | 0.8804347823207505  | 0.7946859903381642  | 0.6847826089835973  | 0.336956521883103   | 0.021739130434782608|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc4865d42a7b96bf49940e03a1d33c3e32ae20f8de81d71d36a73e19abe31532"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
